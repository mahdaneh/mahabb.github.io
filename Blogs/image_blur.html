<html>
<head>
  <!--<script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script>
  <script type="text/javascript"
    src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>-->

    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>

  <script type="text/javascript"
          src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
  <link rel="stylesheet" href="../css/blog_style.css">

    <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  </head>


<body>

  <div class="wrapper">
  <header class="TOC">
    <h2> Table of Content </h2>
    <ul >

    <li><h3> <a href="#s1"> 1. Fourier transform </a></h3></li>
    <li><h3> <a href="#s2"> 2. Image blurring </a></h3></li>
        <ul>
            <li> <a href="#s3"> 2.1. Python code snippet</a></li>

        </ul>
        <li><h3><a href="#s5"> 3. Image registeration</a></h3></li>
        <ul>
        <li><a href="s6">3.1. Python code snippet</a></li>
        </ul>

  </ul>
  <a href="../index.html">
    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-house-fill" viewBox="0 0 16 16">
    <path fill-rule="evenodd" d="M8 3.293l6 6V13.5a1.5 1.5 0 0 1-1.5 1.5h-9A1.5 1.5 0 0 1 2 13.5V9.293l6-6zm5-.793V6l-2-2V2.5a.5.5 0 0 1 .5-.5h1a.5.5 0 0 1 .5.5z"/>
    <path fill-rule="evenodd" d="M7.293 1.5a1 1 0 0 1 1.414 0l6.647 6.646a.5.5 0 0 1-.708.708L8 2.207 1.354 8.854a.5.5 0 1 1-.708-.708L7.293 1.5z"/>
  </svg>
  Home</a>
  </header>



    <section>
        <h1> Fourier transform for image manipulation</h1>

        <h2 id="s1">1. Quick introduction: Fourier transform</h2>
        <p>
        The key point of this post is to review image manipulation, including efficient <b>image blurring and images registration</b>, through using Fourier transform .
        Recall that discrete Fourier aims to transfer a 2D image from spatial domain (pixel space), i.e. $I(x,y)$ into frequency domain, i.e. $F(u,v)$,
        where each point ($u,v$) in $F$
        represents a particular frequency.
 For a given pair of frequencies $(u,v), where $$u\in\{1,\dots,N\},v\in\{1,\dots,M\}$ with $N, M$ is size of image $I$,
        the Fourier transform of $I(x,y)$ is obtained as follows:
        </p>

$$F(u,v) = \sum_{x=0}^{N-1}\sum_{y=0}^{M-1}I(x,y)\exp(-j2\pi(\frac{ux}{N}+\frac{vy}{M})).$$

Interestingly, $F(0,0)$, which shows zero frequency in the image, is the summation of image's pixels intensity. Note that, for an image of size $NxM$, its representation in frequency domain has the same size.

        <p>The image in frequency domain are complex number, consisting of two parts: a real part (denoted as $R(u,v)$) and an imaginary part ($I(u,v)$), i.e. $F(u,v) = R(u,v) + I(u,v)j$.
            As it is shown in <a href="#fig1">Figure 1</a>, the complex number of $F(u,v)$ can be represented in polar coordinate system, leading to:</p>

$$F(u,v) =  \underbrace{|F(u,v)|}_{\text{Magnitude}}\exp(j \underbrace{\phi(u,v)}_{\text{phase}}),$$
        where $|F(u,v)|=\sqrt{R(u,v)^2+I(u,v)^2}$ and $\phi(u,v) = \arctan(I(u,v)/R(u,v))$ are called magnitude (spectrum) and phase at a given frequency $u,v$, respectively.



<div class="parent">
        <div class="text">
      <figure>
      <img width="30%" src="../images/image_blur/polar.png" class='center'>

          <figcaption><span id="fig1">Figure 1</span>: representing a complex number ($x+iy$) in polar coordinate $re^{j\theta}$. </figcaption>
</figure>
        </div>
      </div>


<h2 id="s2">2. Image blurring </h2>
<p>
A blurred image can be achieved by obscuring high frequencies of a given image in the frequency domain. To filter out high frequencies, different variants of low pass filter exist, such as Gaussian
    low pass (GLP) and ideal filters, among others.

    For example, the 1st image at 2nd row in <a href="#fig2">figure 2</a> is a Gaussian low pass filter with band-width 10.
    This is equivalent to removing edges in the spatial domains,
    which can equivalently be achieved by convolving the image with a spatial kernel filter (e.g. mean filter). However, it is interesting to note that
    image blurring can simply be done by one simple multiplication in frequency domain.
</p>
        <div>
            <h3 id="s3">2.1. Code snippet for image blurring</h3>
            Here, we define a GLP in frequency domain with a specified band-width, then multiply it by an image, represented in its frequency domain, to obtain a smooth (blurred) image. Note an image in frequency domain is zero-centered so that its zero frequency
            is placed at center of image (using fftshift function from fft package of numpy).
<pre><code class="python">import numpy as np
from numpy import fft
def Gaussian_filter(shape, kernel_width, Low=True ):

    X,Y=np.meshgrid(range(shape[1]), range(shape[0]))
    # center of image
    Cx , Cy =   shape[1]/2, shape[0]/2
    # Gaussian filter with given kernel_width
    fltr = np.exp(-((X-Cx)**2+(Y-Cy)**2)/(2*(kernel_width)**2))

    # high pass filter is simply 1-fltr
    if not Low:
        fltr = 1-fltr

    return fltr

orig_frq = np.fft.fftshift(np.fft.fft2(I)) #computing 2D fft of the given image using numpy, then zero-center shifting it.
GLP_10 = Gaussian_filter(I.shape, 10)
filter_img_frq=orig_frq* GLP_10
# back the filtered image to spatial domain by inverse of 2D fft
filter_img_spt=np.fft.ifft2(np.fft.ifftshift(filter_img_frq));
</code></pre>

        </div>
            <h3 id ="s4"> 2.2. Results</h3>
<p>
         In <a href="#fig2">figure 2</a>, the 1st row shows the input image, the filtered image, their difference (removed pixel).
              2nd row represents a Gaussian low pass filter (band-width=10) and log of amplitude ($log |F|$) of the above images in frequency domain. Similarly,
              the 3rd row exhibits the corresponding images by their phase in frequency domain.
    The last column represents densities of pixel intensity (1st row), amplitude (2nd row) and phase (third row)
    of the original image and the filtered one.

</p>
<div class="parent">
        <div class="text">
      <figure>
      <img width="100%" src="../images/image_blur/low10_orig.png" class="center">
          <figcaption><span id="fig2">Figure 2</span>:
              Image blurring; using a low pass filter (kernel width= 10). 1st row: original image, filtered one, and their difference; 2nd row:
              amplitude of the images, 3rd row: phase of the images. Note that intensity of phases of the images (original image and the blurred one) are identical.  </figcaption>
</figure>
        </div>
 </div>
<p>
In <a href="#tb1">figure 3</a>,  each row is exhibiting the original image (1st column), its filtered image (2nd column) using
        a Gaussian low pass (GLP) filter (with a given kernel width), difference between the original image and its filtered one (3rd column).
    and (4th column) pixel density of images in the 1st and 2nd columns.</p>
        <div class="info">
  <p>  Notice that the GLP filter with larger (smaller)
        kernel width leads to less (higher) blurriness,
        meaning it allows to pass more (less) higher frequencies.</p>
</div>


    <table id="tb1">

        <tr>
            <td style="font-size:12px; color:red;"> band-width= 1 </td>
        <td>

            <img width="70%" src="../images/image_blur/low1.png" class="center" >

        </td></tr>

        <tr>
            <td style="font-size:12px; color:red;"> band-width= 5 </td>
        <td>
            <img width="70%" src="../images/image_blur/low5.png" class="center">
        </td></tr>

        <tr>
            <td style="font-size:12px; color:red;"> band-width= 10 </td>
            <td>

            <img width="70%" src="../images/image_blur/low10.png" class="center">
        </td>

        </tr>
    <caption style="caption-side:bottom">Figure 3:  Gaussian LP (GLP)
        filters with various kernel bandwidths leads to different level of blurriness.</caption>
    </table>


<h2 id="s5">3. Image registration</h2>
       <p> Image registration tends to align two images through affine transformation including translation, rotation, sheer, and etc.
            Here, we see how to register two translated images using Fourier transform, which is simple and efficient.
        Consider two images $I$ and $I_1$ that the latter is the translated version of the former, i.e. $I_1(x,y) = I(x-x_0, y-y_0)$.
           <b>Phase only correlation</b> can be used to obtain the precise values for $(x_0, y_0)$. Specifically, by representing the images
        in their frequency domain, we have $F_1(u,v) = e^{-j(ux_0+vy_0)} F(u,v)$. As it can be seen, magnitude of the images are equal, while their phases are different.
           Thus, their phase difference can be used to estimate the amount of translation. But how exactly? regarding cross-correlation between $F$ and $F_2$, we have:

        $$C(u,v)=\frac{F(u,v)F^{*}_{1}(u,v)}{|F(u,v)||F^{*}_{1}(u,v)|}= e^{-j2\pi(\frac{u}{N}x_0+\frac{v}{M}y_0)}$$

        Interestingly, inverse of Fourier transform of $C(u,v)$ leads to delta function $c(x,y) = \delta(x-x_0, y-y_0)$, which has
           only 1 at entry $(x_0,y_0)$. Therefore, the values of translation (displacement) is $\arg\max c(x,y)$.
</p>
        <h3 id="s6"> 3.1. Python code snippet </h3>
        <p>the following code can be used to find the amount of displacement, then translate the first image accordingly.</p>
<pre><code class="python">
    import numpy as np
    import cv2
    def trans_value(I1, I2):

    #im1: convert to rgb2gray
    if np.ndim(I1)==3:
        I1 = I1[:,:,0]

    #im2: convert to rgb2gray
    if np.ndim(I2)==3:
        I2 = I2[:,:, 0]

    #compute fft of im1
    I1_f = (fft.fft2(I1))
    #compute phase of fft(im1)
    phase_1= np.angle(I1_f)

    #the above operations repeated for im2
    I2_f = (fft.fft2(I2))
    phase_2 = np.angle(I2_f)

    #compute difference in the phase of images as follows
    diff_phase = np.exp(1j*(phase_1-phase_2))

    #inverse of fft, then shift it
    poc = fft.fftshift(fft.ifft2(diff_phase))


    #finally find the peak in poc
    #index of maximum value in matrix poc shows translation values (ty,tx)
    ty,tx  = np.unravel_index(poc.argmax(), poc.shape)

    # origin is now at upper left corner
    ty = (-ty+int(I1.shape[0]//2))
    tx = (-tx+int(I1.shape[1]//2))

    # define translation matrix
    T = np.float32([[1, 0, tx], [0, 1, ty]])

    img_translation = cv2.warpAffine(I1, T, (I1.shape[1], I1.shape[0]))

    return tx,ty, poc, img_translation
</code></pre>

        <h3 id="s7">Results</h3>
        Two images are given, one is shifted version of the other. Using POC (phase only correlation), we can find how much
        the first is <shifted class=""></shifted>
<div class="parent">
        <div class="text">
      <figure>
      <img width="100%" src="../images/image_blur/translation.png" class="center">
          <figcaption><span id="fig3">Figure 4: finding the amount of translation between left and middle images using POC method.
              Then applying the translation matrix to the left image to translate it (resulting to right image). </span></figcaption>
</figure>
        </div>
 </div>

    </section>
  </div>



</body>
</html>