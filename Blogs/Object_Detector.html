
---

layout: default
---

<head>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript"
  src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>


    <section>
      <h1>Performance degradation of a SOTA object detecor trained on a dataset with missing-labels</h1>
  <h2> Introduction</h2>
<p>
  
  Modern CNN-based object detectors such as faster R-CNN and YOLO achieve remarkable performance when trained 
  on fully labeled large-scale datasets. 
  On the one hand, collecting a dataset with full annotations, specifically bounding boxes around Objects of Interest (OoI), can be a tedious and costly process.
  On the other hand, the object detectors such as R-CNN and YOLO show that their performance is dependent on having access to such fully labeled datasets. 
  In other words, training them on partially labelled datasets (i.e. containing instances with missing-labels) leads to a drop in generalization performance.


  
  
  <!--When \(a \ne 0\), there are two solutions to \(ax^2 + bx + c = 0\) and they are
  \[x = {-b \pm \sqrt{b^2-4ac} \over 2a}.\]-->
</p>
  
    Several scenarios can lead to a parially labelled dataset:
    <ul>
      <li><b>Unintentional error in labelling</b></li>
      <li> <b>Partial annotation policy </b>:To reduce annotation cost, "partial annotation policy" considers 
        to annotate only one instance of each object presented in a given image. For example, in an image containing a herd of sheep, only one sheep is annotated, instead of
        fully annotating all the sheep instances in the image. This policy causes some missing bounding box
        annotations but interestingly no missing image-level labels as at least one instance of each existing object in the given image is annotated.</li>
      <li><b>Merged dataset</b>  we aim at combining several datasets from similar (or the same) contexts but with disjoint 
        (or partially disjoint) sets of Objects of Interest (OoI), in order to <b>efficiently</b> construct a larger dataset that
        includes a wider range of objects of interest. For instance, Kitti and German Traffic Signs are
        two different datasets with two disjoint sets of OoIs that could be merged to cover a wider spectrum of objects appearing on roads. Furthermore,
        merging the datasets that include the object of interest from across different domains --i.e. the objects appeared in different poses, illuminations, styles, 
        etc-- have the potential to also mitigate the domain-shift challenge. <b>To read more about merged datasets, interested readers can 
        read our <a href="https://arxiv.org/abs/2005.11549"> article </a>.</b></li>
      
      </ul>
      
      <h2> The Impact of Missing-label Instances on Performance</h2>
      
      As stated earlier, missing-label instances (called UPIs-- Unlabelled Positive Instances)
      can cause false negative signals in the training. In the following, we demonstrate how the missing-label instances cause a drop in performance 
      (i.e. mean average of precision ) of object detectors, particularly YOLO and faster R-CNN. <b>to be continued</b>
      
    </section>

